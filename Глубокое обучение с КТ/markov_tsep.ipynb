{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8s63yrt9-z7",
        "outputId": "07a17bb4-fe28-4047-a228-0f4d46508944"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GMiw3aTvhH6t"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import random\n",
        "\n",
        "def remove_bracketed_sections(text):\n",
        "    text = re.sub(r'\\[.?\\]', '', text)\n",
        "    table = str.maketrans({';': '', '\"': '', ' ': ' '})\n",
        "    return text.translate(table)\n",
        "\n",
        "def preprocess_lyrics(text):\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "    text = re.sub(r'\\(.?\\)', '', text)\n",
        "    text = re.sub(r'\\s\\n\\s', '\\n', text)\n",
        "    return text.strip()\n",
        "\n",
        "df = pd.read_csv('slava_kpss_lyrics.csv')\n",
        "df['lyrics'] = df['lyrics'].apply(remove_bracketed_sections)\n",
        "df['lyrics'] = df['lyrics'].apply(preprocess_lyrics)\n",
        "\n",
        "all_sentences = []\n",
        "for s in df['lyrics'].dropna():\n",
        "    all_sentences += sent_tokenize(s, language='russian')\n",
        "\n",
        "all_songs = \"\\n\".join(all_sentences)\n",
        "with open(\"all_songs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(all_songs)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MarkovChain:\n",
        "    def __init__(self, order=2):\n",
        "        self.order = order\n",
        "        self.chain = defaultdict(Counter)\n",
        "        self.words = []\n",
        "\n",
        "    def train(self, text_data):\n",
        "        for sentence in text_data:\n",
        "            words = sentence.split()\n",
        "            if len(words) < self.order + 1:\n",
        "                continue\n",
        "\n",
        "            words = ['<START>'] * self.order + words + ['<END>']\n",
        "            self.words.extend(words)\n",
        "\n",
        "            for i in range(len(words) - self.order):\n",
        "                key = tuple(words[i:i + self.order])\n",
        "                next_word = words[i + self.order]\n",
        "                self.chain[key][next_word] += 1\n",
        "\n",
        "    def get_next_word(self, context, temperature=1.0):\n",
        "        word_counts = self.chain[context]\n",
        "        words = list(word_counts.keys())\n",
        "        counts = list(word_counts.values())\n",
        "        if not words:\n",
        "            return '<END>'\n",
        "        counts = np.array(counts, dtype=float)\n",
        "        log_probs = np.log(counts + 1e-8) / temperature\n",
        "        probs = np.exp(log_probs - np.max(log_probs))\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(words, p=probs)\n"
      ],
      "metadata": {
        "id": "rA8CVszI8ypn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = MarkovChain(order=2)\n",
        "markov_model.train(all_sentences)"
      ],
      "metadata": {
        "id": "V8IfJw_49Mkr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_markov(model, start_string=\"\", temperature=0.5, max_length=100):\n",
        "    if start_string.strip():\n",
        "        # Если есть начальная строка, использую ее\n",
        "        words = start_string.strip().split()\n",
        "        generated_words = words.copy()\n",
        "        if len(words) >= model.order:\n",
        "            context = tuple(words[-model.order:])\n",
        "        else:\n",
        "            # Если слов меньше чем order, дополняем START токенами\n",
        "            context = tuple(['<START>'] * (model.order - len(words)) + words)\n",
        "    else:\n",
        "        context = tuple(['<START>'] * model.order)\n",
        "        generated_words = []\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        next_word = model.get_next_word(context, temperature=temperature)\n",
        "        if next_word == '<END>':\n",
        "            break\n",
        "        if next_word != '<START>':\n",
        "            generated_words.append(next_word)\n",
        "        context = context[1:] + (next_word,)\n",
        "\n",
        "    return ' '.join(generated_words)"
      ],
      "metadata": {
        "id": "P45BIUee9Zrg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_texts = [\n",
        "    \"На пятки наступает\",\n",
        "    \"Я не тот, кем был раньше\",\n",
        "    \"Это всё просто мельтешение\"\n",
        "]\n",
        "for start_text in start_texts:\n",
        "    print(f\"\\nНачальный текст: '{start_text}'\")\n",
        "    generated_text = generate_text_markov(\n",
        "        markov_model,\n",
        "        start_text,\n",
        "        temperature=0.5,\n",
        "        max_length=50\n",
        "    )\n",
        "\n",
        "    print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZg_XAFZ9TKt",
        "outputId": "2dccf89e-274c-49be-9c60-af66ff369e0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Начальный текст: 'На пятки наступает'\n",
            "На пятки наступает духовная нищанка Сыграй со мной в пятнашки, я — весёлая Каштанка Гоняюсь по двору за собственным хвостом И так покуда не помру, и, видно, в этом весь прикол [Припев] А дедушка ждёт, а дедушка плачет Но для ЖЭКа его слёзы мало чего значат [Куплет] Он думал, знает он про тебя\n",
            "\n",
            "Начальный текст: 'Я не тот, кем был раньше'\n",
            "Я не тот, кем был раньше По мне не суйся к нам придёт, тот охуеет от того, что ты вкусняшка Ты собака, я упряжка, спускай вперёд Годики своё берут, скажешь: Скоро наберу Как крестьяне заберу, мы ведём войну Мой крю строго на говне Говорим расизму: «Нет» Защищал Россию дед От таких как я закрыты Так что\n",
            "\n",
            "Начальный текст: 'Это всё просто мельтешение'\n",
            "Это всё просто мельтешение жизни Отмечаю вещи и мысли серьезные А только белый синий красный, и были правы все фантасты Айн Рэнд и Голдинг, Хаксли, что социум как антипод прекрасного и справедливого Похорони меня, где ветер в ивах нежно шепчет не буди Не будь самим собой, а стань другим Стань чище, тише, есть вещи\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_markov_model(model, filepath='markov_model.pkl'):\n",
        "    with open(filepath, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "def load_markov_model(filepath='markov_model.pkl'):\n",
        "    with open(filepath, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model\n",
        "save_markov_model(markov_model)"
      ],
      "metadata": {
        "id": "lLeb174J9deZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}